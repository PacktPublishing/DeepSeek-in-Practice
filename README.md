<h1 align="center">
DeepSeek in Practice, First Edition</h1>
<p align="center">This is the code repository for <a href ="https://www.packtpub.com/en-us/product/deepseek-in-practice-9781806020843"> DeepSeek in Practice, First Edition</a>, published by Packt.
</p>

<h2 align="center">
From basics to fine-tuning, distillation, agent design, and prompt engineering of open source LLM
</h2>
<p align="center">
Andy Peng, Alex Strick van Linschoten, Duarte O. Carmo</p>

<p align="center">
   <a href="https://packt.link/I1tSU" alt="Discord" title="Learn more on the Discord server"><img width="32px" src="https://cliply.co/wp-content/uploads/2021/08/372108630_DISCORD_LOGO_400.gif"/></a>
  &#8287;&#8287;&#8287;&#8287;&#8287;
  <a href="https://packt.link/free-ebook/9781806020850"><img width="32px" alt="Free PDF" title="Free PDF" src="https://cdn-icons-png.flaticon.com/512/4726/4726010.png"/></a>
 &#8287;&#8287;&#8287;&#8287;&#8287;
  <a href="https://packt.link/gbp/9781806020850"><img width="32px" alt="Graphic Bundle" title="Graphic Bundle" src="https://cdn-icons-png.flaticon.com/512/2659/2659360.png"/></a>
  &#8287;&#8287;&#8287;&#8287;&#8287;
   <a href="https://www.amazon.com/DeepSeek-Practice-fine-tuning-distillation-engineering/dp/1806020858/ref=tmm_pap_swatch_0?_encoding=UTF8&sr=8-1"><img width="32px" alt="Amazon" title="Get your copy" src="https://cdn-icons-png.flaticon.com/512/15466/15466027.png"/></a>
  &#8287;&#8287;&#8287;&#8287;&#8287;
</p>
<details open>
  <summary><h2>About the book</summary>
<a href="https://www.packtpub.com/en-us/product/deepseek-in-practice-9781806020843">
<img src="https://m.media-amazon.com/images/I/81jjIsEALkL._SL1500_.jpg" alt="DeepSeek in Practice, First Edition" height="256px" align="right">
</a>

Learn how to build, fine-tune, and deploy AI systems using DeepSeek, one of the most influential open-source large language models available today. This book guides you through real-world DeepSeek applications—from understanding its core architecture and training foundations to developing reasoning agents and deploying production-ready systems.
Starting with a concise synthesis of DeepSeek's research, breakthroughs, and open-source philosophy, you’ll progress to hands-on projects including prompt engineering, workflow design, and rationale distillation. Through detailed case studies—ranging from document understanding to legal clause analysis—you’ll see how to use DeepSeek in high-value GenAI scenarios.
You’ll  also learn to build sophisticated agent workflows and prepare data for fine-tuning. By the end of the book, you’ll have the skills to integrate DeepSeek into local deployments, cloud CI/CD pipelines, and custom LLMOps environments.
Written by experts with deep knowledge of open-source LLMs and deployment ecosystems, this book is your comprehensive guide to DeepSeek’s capabilities and implementation.
</details>
<details open>
  <summary><h2>Key Learnings</summary>
<ul>

<li>Discover DeepSeek's unique traits in the LLM landscape</li>

<li>Compare DeepSeek's multimodal features with leading models</li>

<li>Consume DeepSeek via the official API, Ollama, and llama.cpp</li>

<li>Use  DeepSeek for coding, document understanding, and creative ideation</li>

<li>Integrate DeepSeek with third-party platforms like OpenRouter and Cloudflare</li>

<li>Distill and deploy DeepSeek models into production environments</li>

<li>Identify when and where to use DeepSeek</li>

<li>Understand DeepSeek's open philosophy</li>

</ul>

  </details>

<details open>
  <summary><h2>Chapters</summary>


| Chapters | Colab | Kaggle | Gradient | Studio Lab |
| :-------- | :-------- | :------- | :-------- | :-------- |
| **Chapter 1: What is DeepSeek?** | | | | |
| **Chapter 2: Deep Dive into DeepSeek** | | | | |
| **Chapter 3: Prompting DeepSeek** | | | | |
| **Chapter 4: Using DeepSeek: Case Studies** | | | | |
| **Chapter 5: Building with DeepSeek** | | | | |
| <ul><li>01-initial-prototype.ipynb</li></ul> | <a href="https://colab.research.google.com/github/PacktPublishing/DeepSeek-in-Practice/blob/main/Chapter05/01-initial-prototype.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"></a><br> | <a href="https://www.kaggle.com/kernels/welcome?src=https://github.com/PacktPublishing/DeepSeek-in-Practice/blob/main/Chapter05/01-initial-prototype.ipynb"><img src="https://kaggle.com/static/images/open-in-kaggle.svg" alt="Open In Kaggle"></a><br> | <a href="https://gradient.run/notebook/github.com/PacktPublishing/DeepSeek-in-Practice/blob/main/Chapter05/01-initial-prototype.ipynb"><img src="https://assets.paperspace.io/img/gradient-badge.svg" alt="Open In Gradient"></a><br> | <a href="https://studiolab.sagemaker.aws/import/github/PacktPublishing/DeepSeek-in-Practice/blob/main/Chapter05/01-initial-prototype.ipynb"><img src="https://studiolab.sagemaker.aws/studiolab.svg" alt="Open In Studio Lab"></a><br> |
| <ul><li>07-aws-deployment.ipynb</li></ul> | <a href="https://colab.research.google.com/github/PacktPublishing/DeepSeek-in-Practice/blob/main/Chapter05/07-aws-deployment.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"></a><br> | <a href="https://www.kaggle.com/kernels/welcome?src=https://github.com/PacktPublishing/DeepSeek-in-Practice/blob/main/Chapter05/07-aws-deployment.ipynb"><img src="https://kaggle.com/static/images/open-in-kaggle.svg" alt="Open In Kaggle"></a><br> | <a href="https://gradient.run/notebook/github.com/PacktPublishing/DeepSeek-in-Practice/blob/main/Chapter05/07-aws-deployment.ipynb"><img src="https://assets.paperspace.io/img/gradient-badge.svg" alt="Open In Gradient"></a><br> | <a href="https://studiolab.sagemaker.aws/import/github/PacktPublishing/DeepSeek-in-Practice/blob/main/Chapter05/07-aws-deployment.ipynb"><img src="https://studiolab.sagemaker.aws/studiolab.svg" alt="Open In Studio Lab"></a><br> |
| **Chapter 6: Agents with DeepSeek** | | | | |
| <ul><li>01-evaluator-optimizer.ipynb</li></ul> | <a href="https://colab.research.google.com/github/PacktPublishing/DeepSeek-in-Practice/blob/main/Chapter06/01-evaluator-optimizer.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"></a><br> | <a href="https://www.kaggle.com/kernels/welcome?src=https://github.com/PacktPublishing/DeepSeek-in-Practice/blob/main/Chapter06/01-evaluator-optimizer.ipynb"><img src="https://kaggle.com/static/images/open-in-kaggle.svg" alt="Open In Kaggle"></a><br> | <a href="https://gradient.run/notebook/github.com/PacktPublishing/DeepSeek-in-Practice/blob/main/Chapter06/01-evaluator-optimizer.ipynb"><img src="https://assets.paperspace.io/img/gradient-badge.svg" alt="Open In Gradient"></a><br> | <a href="https://studiolab.sagemaker.aws/import/github/PacktPublishing/DeepSeek-in-Practice/blob/main/Chapter06/01-evaluator-optimizer.ipynb"><img src="https://studiolab.sagemaker.aws/studiolab.svg" alt="Open In Studio Lab"></a><br> |
| <ul><li>02-orchestrator-worker.ipynb</li></ul> | <a href="https://colab.research.google.com/github/PacktPublishing/DeepSeek-in-Practice/blob/main/Chapter06/02-orchestrator-worker.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"></a><br> | <a href="https://www.kaggle.com/kernels/welcome?src=https://github.com/PacktPublishing/DeepSeek-in-Practice/blob/main/Chapter06/02-orchestrator-worker.ipynb"><img src="https://kaggle.com/static/images/open-in-kaggle.svg" alt="Open In Kaggle"></a><br> | <a href="https://gradient.run/notebook/github.com/PacktPublishing/DeepSeek-in-Practice/blob/main/Chapter06/02-orchestrator-worker.ipynb"><img src="https://assets.paperspace.io/img/gradient-badge.svg" alt="Open In Gradient"></a><br> | <a href="https://studiolab.sagemaker.aws/import/github/PacktPublishing/DeepSeek-in-Practice/blob/main/Chapter06/02-orchestrator-worker.ipynb"><img src="https://studiolab.sagemaker.aws/studiolab.svg" alt="Open In Studio Lab"></a><br> |
| <ul><li>03-tool-calling-agent.ipynb</li></ul> | <a href="https://colab.research.google.com/github/PacktPublishing/DeepSeek-in-Practice/blob/main/Chapter06/03-tool-calling-agent.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"></a><br> | <a href="https://www.kaggle.com/kernels/welcome?src=https://github.com/PacktPublishing/DeepSeek-in-Practice/blob/main/Chapter06/03-tool-calling-agent.ipynb"><img src="https://kaggle.com/static/images/open-in-kaggle.svg" alt="Open In Kaggle"></a><br> | <a href="https://gradient.run/notebook/github.com/PacktPublishing/DeepSeek-in-Practice/blob/main/Chapter06/03-tool-calling-agent.ipynb"><img src="https://assets.paperspace.io/img/gradient-badge.svg" alt="Open In Gradient"></a><br> | <a href="https://studiolab.sagemaker.aws/import/github/PacktPublishing/DeepSeek-in-Practice/blob/main/Chapter06/03-tool-calling-agent.ipynb"><img src="https://studiolab.sagemaker.aws/studiolab.svg" alt="Open In Studio Lab"></a><br> |
| **Chapter 7: DeepSeek-Driven Fine-Tuning of Gemma 3 for Legal Reasoning** | | | | |
| **Chapter 8: Deploying DeepSeek Models** | | | | |






</details>


<details open>
  <summary><h2>Requirements for this book</summary>
To get the most out of this book, ensure you have the following:

### Software Requirements
- Hands-on experience with **Python**, working with **APIs**, and tools such as **Ollama** or **llama.cpp**
- Familiarity with tools and platforms like **uv** and **Docker**
- A solid understanding of **machine learning concepts**

### Hardware Requirements
- A computer capable of running local LLMs using tools like Ollama or llama.cpp
- At least **8–16 GB of RAM**, depending on the model sizes you plan to run
- Adequate **CPU/GPU resources** for development, testing, and experimentation

  </details>



<details>
  <summary><h2>Get to know Authors</h2></summary>

_Andy Peng_ is a Senior Engineer at Amazon, leading both 0-to-1 innovation and 10x scaling across AWS Bedrock and SageMaker. He specializes in large language model inference optimization and evaluation for models like DeepSeek, Qwen, and Claude. His work spans Amazon S3, AWS Fargate, App Runner, Alexa Health & Wellness, and fintech. A NeurIPS 2025 Chair and program committee member for ICML, ICLR, KDD, and NeurIPS, he contributes to CNCF and the Linux Foundation, mentors at the University of Washington, and serves as Resident Expert at the AI2 Incubator.

_Alex Strick van Linschoten_ is a Machine Learning Engineer at ZenML. He led the development of the LLMOps Database, a comprehensive collection of over 800 case studies examining LLMOps and GenAI implementations in production environments. His work focuses on bridging the gap between machine learning research and production deployment, particularly within the LLMOps space.
He transitioned to software engineering after earning a PhD in History and spending 15 years living and working as a historian and researcher in Afghanistan. He has authored, edited, and translated several books based on his historical research and is currently based in Delft, the Netherlands.

_Duarte O. Carmo_ is a technologist from Lisbon, Portugal, now based in Copenhagen, Denmark. For the past decade, he's worked at the intersection of machine learning, artificial intelligence, software, data, and people. He has helped solve problems for both global corporations and small startups across industries such as healthcare, finance, agriculture, and advertising. His approach to solving tough problems always starts with the same thing: people. For the past five years, he's been running his one-man consulting company, working with clients of all sizes and across industries. He's also a regular speaker in the Python and machine learning communities and an active writer.



</details>
<details>
  <summary><h2>Other Related Books</h2></summary>
<ul>

  <li><a href="https://www.packtpub.com/en-us/product/building-agentic-ai-systems-first-edition/9781803238753">Building Agentic AI Systems, First Edition</a></li>

  <li><a href="https://www.packtpub.com/en-us/product/llms-in-enterprise-first-edition/9781836203070">LLMs in Enterprise, First Edition</a></li>

</ul>

</details>
